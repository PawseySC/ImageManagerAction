name: Image Manager CI/CD Pipeline
# Version 2.0.0 - Updated for Image Manager Integration
# This workflow processes uploads from Image Manager tool
# Triggered by pushes to cicd-* branches with manifest.json configuration
# Supports branch formats: cicd-main/feature (preferred) or cicd-main-feature (legacy)

on:
  push:
    branches:
      - 'cicd-*'
      - 'cicd-*/**'
      - 'cicd-**'

permissions:
  contents: read
  security-events: write  # Required for uploading SARIF results to GitHub Security tab
  actions: read           # Required for accessing workflow run information

jobs:
  PREPARE-job:
    runs-on: ubuntu-latest
    outputs:
      # Job Output Variables:
      # - proceed_valid: Whether to proceed with build (true/false)
      # - main: Main software name from manifest (e.g., "python")
      # - feature: Feature name from manifest (e.g., "cuda-hpc-python")
      # - version: Semver version from manifest (e.g., "1.2.3")
      # - devmode: Development mode flag (true/false)
      # - noscan: Skip security scan flag (true/false)
      # - platform: Target platform (x86/arm)
      # - shpc: SHPC deployment flag (true/false)
      # - targets: JSON array of target registries
      # - private_targets: JSON array of private target registries
      # - branch_path: Directory path based on branch (e.g., "python/cuda-hpc-python")
      # - dockerfile_path: Path to Dockerfile (e.g., "python/cuda-hpc-python/Dockerfile")
      # - correlation_id: Unique ID for tracking
      # Registry availability flags:
      # - dockerhub_available: Whether Docker Hub credentials are available
      # - quayio_available: Whether Quay.io credentials are available
      # - setonixreg_available: Whether Setonix Registry credentials are available
      # Template/Matrix outputs:
      # - build_matrix: JSON matrix configuration for multi-variant builds
      # - has_template: Whether template field exists in manifest
      # - variant_count: Number of build variants
      proceed_valid: ${{ steps.validate_manifest.outputs.proceed_valid }}
      main: ${{ steps.validate_manifest.outputs.main }}
      feature: ${{ steps.validate_manifest.outputs.feature }}
      version: ${{ steps.validate_manifest.outputs.version }}
      devmode: ${{ steps.validate_manifest.outputs.devmode }}
      noscan: ${{ steps.validate_manifest.outputs.noscan }}
      platform: ${{ steps.validate_manifest.outputs.platform }}
      shpc: ${{ steps.validate_manifest.outputs.shpc }}
      targets: ${{ steps.validate_manifest.outputs.targets }}
      private_targets: ${{ steps.validate_manifest.outputs.private_targets }}
      branch_path: ${{ steps.validate_manifest.outputs.branch_path }}
      dockerfile_path: ${{ steps.validate_manifest.outputs.dockerfile_path }}
      correlation_id: ${{ steps.validate_manifest.outputs.correlation_id }}
      date: ${{ steps.date.outputs.date }}
      dockerhub_available: ${{ steps.check_vars_secrets.outputs.dockerhub_available }}
      quayio_available: ${{ steps.check_vars_secrets.outputs.quayio_available }}
      setonixreg_available: ${{ steps.check_vars_secrets.outputs.setonixreg_available }}
      build_matrix: ${{ steps.process_template.outputs.matrix }}
      has_template: ${{ steps.process_template.outputs.has_template }}
      variant_count: ${{ steps.process_template.outputs.variant_count }}
    
    steps:
      - name: Initialize runner configuration
        id: set_default_runner_label
        run: |
          echo "runner_label=ubuntu-latest" >> $GITHUB_OUTPUT

      - name: Validate environment credentials
        id: check_vars_secrets
        run: |
          missing_vars=()
          missing_secrets=()

          # check Variables
          if [ -z "${{ vars.DOCKERHUB_USERNAME }}" ]; then
            missing_vars+=("DOCKERHUB_USERNAME")
          fi

          if [ -z "${{ vars.QUAYIO_USERNAME }}" ]; then
            missing_vars+=("QUAYIO_USERNAME")
          fi

          if [ -z "${{ vars.SETONIXREG_USERNAME }}" ]; then
            missing_vars+=("SETONIXREG_USERNAME")
          fi

          if [ -z "${{ vars.ACACIA_BUCKETNAME }}" ]; then
            missing_vars+=("ACACIA_BUCKETNAME")
          fi

          if [ -z "${{ vars.ACACIA_SIF_BUCKETNAME }}" ]; then
            missing_vars+=("ACACIA_SIF_BUCKETNAME")
          fi

          # check Secrets
          if [ -z "${{ secrets.PAT_TOKEN }}" ]; then
            missing_secrets+=("PAT_TOKEN")
          fi

          if [ -z "${{ secrets.DOCKERHUB_TOKEN }}" ]; then
            missing_secrets+=("DOCKERHUB_TOKEN")
          fi

          if [ -z "${{ secrets.QUAYIO_TOKEN }}" ]; then
            missing_secrets+=("QUAYIO_TOKEN")
          fi

          if [ -z "${{ secrets.SETONIXREG_PASS }}" ]; then
            missing_secrets+=("SETONIXREG_PASS")
          fi

          if [ -z "${{ secrets.ACACIA_ACCESS_KEY_ID }}" ]; then
            missing_secrets+=("ACACIA_ACCESS_KEY_ID")
          fi

          if [ -z "${{ secrets.ACACIA_SECRET_ACCESS_KEY }}" ]; then
            missing_secrets+=("ACACIA_SECRET_ACCESS_KEY")
          fi

          # Log status of variables and secrets
          if [ ${#missing_vars[@]} -ne 0 ]; then
            echo "Missing Variables: ${missing_vars[@]}"
          else
            echo "All required variables are set."
          fi
          
          if [ ${#missing_secrets[@]} -ne 0 ]; then
            echo "Missing Secrets: ${missing_secrets[@]}"
          else
            echo "All required secrets are set."
          fi
          
          # Set output flags for conditional job execution
          dockerhub_available=$( [ -n "${{ vars.DOCKERHUB_USERNAME }}" ] && [ -n "${{ secrets.DOCKERHUB_TOKEN }}" ] && echo 'true' || echo 'false' )
          quayio_available=$( [ -n "${{ vars.QUAYIO_USERNAME }}" ] && [ -n "${{ secrets.QUAYIO_TOKEN }}" ] && echo 'true' || echo 'false' )
          setonixreg_available=$( [ -n "${{ vars.SETONIXREG_USERNAME }}" ] && [ -n "${{ secrets.SETONIXREG_PASS }}" ] && echo 'true' || echo 'false' )
          
          echo "dockerhub_available=$dockerhub_available" >> $GITHUB_OUTPUT
          echo "quayio_available=$quayio_available" >> $GITHUB_OUTPUT
          echo "setonixreg_available=$setonixreg_available" >> $GITHUB_OUTPUT
          
          # Log registry availability status
          echo ""
          echo "=== Registry Credentials Check ==="
          if [ "$dockerhub_available" = "true" ]; then
            echo "[âœ“] Docker Hub: Credentials available"
          else
            echo "[âœ—] Docker Hub: Missing credentials (DOCKERHUB_USERNAME or DOCKERHUB_TOKEN)"
          fi
          
          if [ "$quayio_available" = "true" ]; then
            echo "[âœ“] Quay.io: Credentials available"
          else
            echo "[âœ—] Quay.io: Missing credentials (QUAYIO_USERNAME or QUAYIO_TOKEN)"
          fi
          
          if [ "$setonixreg_available" = "true" ]; then
            echo "[âœ“] Setonix Registry: Credentials available"
          else
            echo "[âœ—] Setonix Registry: Missing credentials (SETONIXREG_USERNAME or SETONIXREG_PASS)"
          fi
          echo "==================================="

      - name: Checkout source code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1  # Only need current commit for manifest-based workflow

      - name: Determine branch directory path
        id: parse_branch
        run: |
          # Extract main and feature from branch name
          # Supports formats: cicd-main/feature or cicd-main-feature
          branch_name="${{ github.ref_name }}"
          echo "Branch name: $branch_name"
          
          if [[ ! "$branch_name" =~ ^cicd- ]]; then
            echo "Error: Branch name must start with 'cicd-'"
            exit 1
          fi
          
          # Remove 'cicd-' prefix
          path_part="${branch_name#cicd-}"
          echo "Path part after removing 'cicd-': $path_part"
          
          # Check if path_part contains a forward slash (preferred format: cicd-main/feature)
          if [[ "$path_part" == *"/"* ]]; then
            # Format: cicd-main/feature -> main/feature
            branch_path="$path_part"
            echo "âœ“ Using slash-separated format: $branch_path"
          else
            # Fallback: try to parse cicd-main-feature format
            # This is less reliable but maintained for backwards compatibility
            echo "âš ï¸  Using legacy dash-separated format, consider using cicd-main/feature instead"
            branch_path="$path_part"
          fi
          
          echo "Final branch path: $branch_path"
          echo "branch_path=$branch_path" >> $GITHUB_OUTPUT

      - name: Validate manifest and extract configuration
        id: validate_manifest
        run: |
          branch_path="${{ steps.parse_branch.outputs.branch_path }}"
          manifest_file="${branch_path}/manifest.json"
          
          echo "Looking for manifest at: $manifest_file"
          echo "Searching for Dockerfile variants in: $branch_path"
          
          # Check if manifest.json exists
          if [ ! -f "$manifest_file" ]; then
            echo "Error: manifest.json not found at $manifest_file"
            echo "This workflow requires a manifest.json file in the branch directory."
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Find Dockerfile with case-insensitive search and various extensions
          dockerfile_found=""
          dockerfile_patterns=(
            "${branch_path}/Dockerfile"
            "${branch_path}/dockerfile" 
            "${branch_path}/"*.dockerfile
            "${branch_path}/"*.Dockerfile
            "${branch_path}/"*.[Dd]ockerfile
          )
          
          echo "Searching for Dockerfile with patterns:"
          for pattern in "${dockerfile_patterns[@]}"; do
            echo "  - $pattern"
            for file in $pattern; do
              if [ -f "$file" ]; then
                dockerfile_found="$file"
                echo "âœ“ Found Dockerfile: $dockerfile_found"
                break 2
              fi
            done
          done
          
          # Check if any Dockerfile variant was found
          if [ -z "$dockerfile_found" ]; then
            echo "Error: No Dockerfile found in $branch_path"
            echo "Searched for: Dockerfile, dockerfile, *.dockerfile, *.Dockerfile, *.[Dd]ockerfile"
            echo "This workflow requires a Dockerfile in the branch directory."
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          dockerfile_path="$dockerfile_found"
          echo "Using Dockerfile: $dockerfile_path"
          
          echo "âœ“ Found manifest.json and Dockerfile"
          
          # Parse and validate manifest.json
          echo "Parsing manifest.json..."
          
          # Extract configuration using jq
          main=$(jq -r '.main // empty' "$manifest_file")
          feature=$(jq -r '.feature // empty' "$manifest_file")
          version=$(jq -r '.version // empty' "$manifest_file")
          devmode=$(jq -r '.devmode // false' "$manifest_file")
          noscan=$(jq -r '.noscan // false' "$manifest_file")
          platform=$(jq -r '.platform // "x86"' "$manifest_file")
          shpc=$(jq -r '.shpc // false' "$manifest_file")
          targets=$(jq -c '.targets // []' "$manifest_file")
          private_targets=$(jq -c '."private-targets" // []' "$manifest_file")
          correlation_id=$(jq -r '.metadata.correlation_id // empty' "$manifest_file")
          
          # Validate required fields
          if [ -z "$main" ] || [ "$main" = "null" ]; then
            echo "Error: Missing 'main' field in manifest.json"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          if [ -z "$feature" ] || [ "$feature" = "null" ]; then
            echo "Error: Missing 'feature' field in manifest.json"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          if [ -z "$version" ] || [ "$version" = "null" ]; then
            echo "Error: Missing 'version' field in manifest.json"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Validate version format (semver X.Y.Z)
          if ! echo "$version" | grep -qE '^[0-9]+\.[0-9]+\.[0-9]+$'; then
            echo "Error: Invalid version format '$version'. Expected X.Y.Z"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Validate platform
          if [ "$platform" != "x86" ] && [ "$platform" != "arm" ]; then
            echo "Error: Invalid platform '$platform'. Expected 'x86' or 'arm'"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Validate targets array
          if [ "$targets" = "[]" ] || [ "$targets" = "null" ]; then
            echo "Warning: No targets specified in manifest.json"
          fi
          
          # Validate branch path matches manifest
          expected_path="${main}/${feature}"
          if [ "$branch_path" != "$expected_path" ]; then
            echo "Error: Branch path '$branch_path' doesn't match manifest main/feature '$expected_path'"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "âœ“ Manifest validation passed"
          echo ""
          echo "=== Configuration Summary ==="
          echo "Main: $main"
          echo "Feature: $feature"
          echo "Version: $version"
          echo "Dev Mode: $devmode"
          echo "No Scan: $noscan"
          echo "Platform: $platform"
          echo "SHPC Deploy: $shpc"
          echo "Targets: $targets"
          echo "Private Targets: $private_targets"
          echo "Correlation ID: $correlation_id"
          echo "Branch Path: $branch_path"
          echo "Dockerfile: $dockerfile_path"
          echo "============================"

          # Set outputs
          echo "proceed_valid=true" >> $GITHUB_OUTPUT
          echo "main=$main" >> $GITHUB_OUTPUT
          echo "feature=$feature" >> $GITHUB_OUTPUT
          echo "version=$version" >> $GITHUB_OUTPUT
          echo "devmode=$devmode" >> $GITHUB_OUTPUT
          echo "noscan=$noscan" >> $GITHUB_OUTPUT
          echo "platform=$platform" >> $GITHUB_OUTPUT
          echo "shpc=$shpc" >> $GITHUB_OUTPUT
          echo "targets=$targets" >> $GITHUB_OUTPUT
          echo "private_targets=$private_targets" >> $GITHUB_OUTPUT
          echo "branch_path=$branch_path" >> $GITHUB_OUTPUT
          echo "dockerfile_path=$dockerfile_path" >> $GITHUB_OUTPUT
          echo "correlation_id=$correlation_id" >> $GITHUB_OUTPUT

      - name: Generate date tag
        if: steps.validate_manifest.outputs.proceed_valid == 'true'
        id: date
        run: |
          date_tag=$(date +'%m-%d')
          echo "Date tag: $date_tag"
          echo "date=$date_tag" >> $GITHUB_OUTPUT

      - name: Process template and generate build matrix
        if: steps.validate_manifest.outputs.proceed_valid == 'true'
        id: process_template
        uses: ./.github/actions/process-template
        with:
          manifest_path: ${{ steps.validate_manifest.outputs.branch_path }}/manifest.json
          dockerfile_path: ${{ steps.validate_manifest.outputs.dockerfile_path }}

      - name: Display build matrix configuration
        if: steps.validate_manifest.outputs.proceed_valid == 'true'
        run: |
          echo "=== Build Matrix Configuration ==="
          echo "Has template: ${{ steps.process_template.outputs.has_template }}"
          echo "Variant count: ${{ steps.process_template.outputs.variant_count }}"
          echo ""
          echo "Matrix configuration:"
          echo '${{ steps.process_template.outputs.matrix }}' | jq '.'
          echo "=================================="

  BUILD-job:
    needs: PREPARE-job
    runs-on: setonix-podman02
    if: needs.PREPARE-job.outputs.proceed_valid == 'true'
    strategy:
      matrix: ${{ fromJson(needs.PREPARE-job.outputs.build_matrix) }}
      fail-fast: false
    outputs:
      image_tag: ${{ steps.build_container.outputs.image_tag }}
      image_name: ${{ steps.build_container.outputs.image_name }}
    steps:
      - name: Checkout source code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Compute variant suffix and display build info
        id: compute_variant
        run: |
          set -euo pipefail

          # Get template values from matrix
          template_values='${{ toJson(matrix.values) }}'
          variant_index="${{ matrix.index }}"

          # Compute variant name and suffix from template values
          if [ "${{ needs.PREPARE-job.outputs.has_template }}" = "true" ] && [ "$template_values" != "{}" ]; then
            # Generate variant name from template values (lowercase for container compatibility)
            variant_name=$(echo "$template_values" | jq -r 'to_entries | map(.key + "-" + .value) | join("-")' | tr '[:upper:]' '[:lower:]')
            variant_suffix=$(echo "$template_values" | jq -r 'to_entries | map("-" + .key + "-" + .value) | join("")' | tr '[:upper:]' '[:lower:]')
          else
            variant_name="default"
            variant_suffix=""
          fi

          echo "=========================================="
          echo "Build Environment"
          echo "=========================================="
          echo "Hostname: $(hostname)"
          echo "Building: ${{ needs.PREPARE-job.outputs.main }}/${{ needs.PREPARE-job.outputs.feature }}:${{ needs.PREPARE-job.outputs.version }}${variant_suffix}"
          echo "Platform: ${{ needs.PREPARE-job.outputs.platform }}"
          echo "Correlation ID: ${{ needs.PREPARE-job.outputs.correlation_id }}"
          echo "Variant #${variant_index}: $variant_name"
          echo "=========================================="

          # Export for use in subsequent steps
          echo "VARIANT_SUFFIX=$variant_suffix" >> $GITHUB_ENV
          echo "VARIANT_NAME=$variant_name" >> $GITHUB_ENV

      - name: Apply template values to Dockerfile
        if: needs.PREPARE-job.outputs.has_template == 'true'
        run: |
          set -euo pipefail

          dockerfile="${{ needs.PREPARE-job.outputs.dockerfile_path }}"
          template_values='${{ toJson(matrix.values) }}'

          echo "Processing Dockerfile: $dockerfile"
          echo "Template values: $template_values"

          # Create a backup of original Dockerfile
          cp "$dockerfile" "$dockerfile.original"

          # Parse template values and modify ARG lines in Dockerfile
          echo "$template_values" | jq -r 'to_entries[] | "\(.key)=\(.value)"' | while IFS='=' read -r arg_name arg_value; do
            echo "Replacing ARG $arg_name with value: $arg_value"

            # Use sed to replace ARG lines
            # Pattern: ARG <name>=<any_value> -> ARG <name>=<new_value>
            sed -i "s|^ARG ${arg_name}=.*|ARG ${arg_name}=${arg_value}|g" "$dockerfile"
          done

          echo "âœ“ Dockerfile modifications completed"
          echo ""
          echo "=== Modified ARG lines ==="
          grep "^ARG" "$dockerfile" || echo "No ARG lines found"
          echo "=========================="

      - name: Configure podman environment
        id: setup_env
        run: |
          echo "Setting up container environment variables..."
          
          # Export environment variables
          export XDG_DATA_HOME=/container/${USER}/data
          export XDG_RUNTIME_DIR=/container/${USER}/runtime
          export TMPDIR=/container/${USER}/tmp/
          
          # Create required directories
          mkdir -p ${XDG_DATA_HOME}
          mkdir -p ${XDG_RUNTIME_DIR}
          mkdir -p ${TMPDIR}
          
          # Set up build optimization variables based on system capabilities
          # JOBS: Number of parallel build stages (optimized for 60+ core system)
          # IMAGE_CACHE_REF: Cache reference for registry-based caching (using existing cache structure)
          
          # Simple JOBS setting based on CPU cores
          CPU_CORES=$(nproc)
          echo "Detected CPU cores: $CPU_CORES"
          
          # Simple 2-tier configuration
          if [ "$CPU_CORES" -gt 8 ]; then
            JOBS="16"  # High-core systems
          else
            JOBS="4"   # Standard systems (8 cores and below)
          fi
          
          echo "JOBS setting: $JOBS (based on $CPU_CORES cores)"
          IMAGE_CACHE_REF="${IMAGE_CACHE_REF:-}"  # Will be configured based on image tag and cache directory
          
          # Verify directories and output status
          echo "Environment setup completed:"
          echo "USER: ${USER}"
          echo "XDG_DATA_HOME: ${XDG_DATA_HOME}"
          echo "XDG_RUNTIME_DIR: ${XDG_RUNTIME_DIR}"
          echo "TMPDIR: ${TMPDIR}"
          echo "CPU_CORES: $CPU_CORES"
          echo "JOBS: $JOBS (simplified 2-tier setting)"
          echo "IMAGE_CACHE_REF: ${IMAGE_CACHE_REF:-'auto-configure'}"
          
          # Check if directories exist
          for dir in "${XDG_DATA_HOME}" "${XDG_RUNTIME_DIR}" "${TMPDIR}"; do
            if [ -d "$dir" ]; then
              echo "âœ“ Podman Directory exists: $dir"
            else
              echo "âœ— Podman Directory missing: $dir"
              exit 1
            fi
          done
          
          # Set environment variables for subsequent steps
          echo "XDG_DATA_HOME=${XDG_DATA_HOME}" >> $GITHUB_ENV
          echo "XDG_RUNTIME_DIR=${XDG_RUNTIME_DIR}" >> $GITHUB_ENV
          echo "TMPDIR=${TMPDIR}" >> $GITHUB_ENV
          echo "JOBS=${JOBS}" >> $GITHUB_ENV
          echo "IMAGE_CACHE_REF=${IMAGE_CACHE_REF}" >> $GITHUB_ENV

      - name: Initialize build cache
        id: setup_cache
        run: |
          # Setup podman cache directory
          CACHE_DIR="/container/${USER}/podman-cache"
          mkdir -p "$CACHE_DIR"
          
          # Create cache subdirectories for different cache types
          REGISTRY_CACHE_DIR="$CACHE_DIR/registry"
          BUILD_CACHE_DIR="$CACHE_DIR/build"
          mkdir -p "$REGISTRY_CACHE_DIR" "$BUILD_CACHE_DIR"
          
          echo "[CACHE SETUP]:"
          echo "  Main cache directory: $CACHE_DIR"
          echo "  Registry cache directory: $REGISTRY_CACHE_DIR"
          echo "  Build cache directory: $BUILD_CACHE_DIR"
          
          # Configure podman to use cache
          export TMPDIR="${TMPDIR:-/tmp}"
          
          # Check cache sizes if exist
          if [ -d "$CACHE_DIR" ]; then
            cache_size=$(du -sh "$CACHE_DIR" 2>/dev/null | cut -f1 || echo "0")
            echo "  Current total cache size: $cache_size"
            
            if [ -d "$REGISTRY_CACHE_DIR" ]; then
              reg_cache_size=$(du -sh "$REGISTRY_CACHE_DIR" 2>/dev/null | cut -f1 || echo "0")
              echo "  Registry cache size: $reg_cache_size"
            fi
          else
            echo "  Cache directories created (empty)"
          fi
          
          # Set environment variables for cache directories
          echo "CACHE_DIR=$CACHE_DIR" >> $GITHUB_ENV
          echo "REGISTRY_CACHE_DIR=$REGISTRY_CACHE_DIR" >> $GITHUB_ENV
          echo "BUILD_CACHE_DIR=$BUILD_CACHE_DIR" >> $GITHUB_ENV

      - name: Build container image
        id: build_container
        run: |
          # Get variables from PREPARE-job
          branch_path="${{ needs.PREPARE-job.outputs.branch_path }}"
          dockerfile_path="${{ needs.PREPARE-job.outputs.dockerfile_path }}"
          main="${{ needs.PREPARE-job.outputs.main }}"
          feature="${{ needs.PREPARE-job.outputs.feature }}"
          version="${{ needs.PREPARE-job.outputs.version }}"

          # Create image name from main, feature and variant suffix
          # Format: name-variant:version (variant suffix in name, version in tag)
          base_name="${main}-${feature}"
          image_name="${base_name}${VARIANT_SUFFIX}"
          image_tag="${image_name}:${version}"
          
          # Set up cache tracking (Podman uses native layer caching)
          IMAGE_CACHE_REF="${main}-${feature}:cache"
          
          # Check if we have previous builds for this main/feature combination
          if [ -d "${REGISTRY_CACHE_DIR}/${main}-${feature}" ]; then
            echo "âœ“ Found existing build cache directory for ${main}-${feature}"
            echo "âœ“ Podman will reuse layers from previous builds automatically"
          else
            echo "â„¹ï¸ First build for ${main}-${feature}, creating cache tracking"
          fi
          
          echo "Building container with podman (optimized)..."
          echo "Build context: $branch_path"
          echo "Dockerfile: $dockerfile_path"  
          echo "Image tag: $image_tag"
          echo "Cache reference: $IMAGE_CACHE_REF"
          
          # Advanced build with layer caching and parallel jobs support
          # Note: Podman uses different caching mechanism than Docker BuildKit
          podman build \
            --format=docker \
            --layers \
            --pull=newer \
            ${JOBS:+--jobs "$JOBS"} \
            -f "$dockerfile_path" \
            -t "$image_tag" \
            "$branch_path"
          
          # Verify the image was built
          if podman images | grep -q "${image_name}"; then
            echo "âœ“ Image built successfully: $image_tag"
            
            # Show advanced optimization information
            echo "[LAYER CACHE]: Podman native layer caching enabled"
            echo "[PULL STRATEGY]: newer (only pull if newer than cached)"
            echo "[PARALLEL JOBS]: $JOBS concurrent build stages ($(nproc) cores detected)"
            echo "[CACHE DIRECTORY]: Using existing cache structure at ${CACHE_DIR}"
            echo "[OPTIMIZATION]: Multi-stage builds and layer reuse enabled"
            echo "[FORMAT]: Docker-compatible image format"
            
            # Create cache tracking for next builds
            mkdir -p "${REGISTRY_CACHE_DIR}/${main}-${feature}"
            echo "$(date): Built ${image_tag} with cache ref ${IMAGE_CACHE_REF}" >> "${REGISTRY_CACHE_DIR}/${main}-${feature}/build.log"
            
            # Show all images to see layer reuse
            echo "[ALL IMAGES]:"
            podman images | head -10
          else
            echo "âœ— Failed to build image: $image_tag"
            exit 1
          fi
          
          # Set outputs for next step
          echo "image_tag=$image_tag" >> $GITHUB_OUTPUT
          echo "image_name=$image_name" >> $GITHUB_OUTPUT

      - name: Export image to archive
        id: save_container
        run: |
          # Get variables from previous step
          image_tag="${{ steps.build_container.outputs.image_tag }}"
          image_name="${{ steps.build_container.outputs.image_name }}"
          version="${{ needs.PREPARE-job.outputs.version }}"

          # Define output file: name-variant_version.tar
          # image_name already includes variant suffix
          output_file="${image_name}_${version}.tar"
          
          echo "Saving container to Docker archive..."
          echo "Image: $image_tag"
          echo "Output: $output_file"
          
          # Save with podman using Docker archive format (compatible with Trivy)
          podman save --format docker-archive "$image_tag" -o "$output_file"
          
          # Verify the file was created
          if [ -f "$output_file" ]; then
            file_size=$(ls -lh "$output_file" | awk '{print $5}')
            echo "âœ“ Archive saved successfully: $output_file (Size: $file_size)"
          else
            echo "âœ— Failed to save archive: $output_file"
            exit 1
          fi
          
          # Set outputs
          echo "archive_file=$output_file" >> $GITHUB_OUTPUT
          echo "archive_path=${PWD}/$output_file" >> $GITHUB_OUTPUT

      - name: Upload archive to S3 storage
        id: s3_upload
        uses: ./.github/actions/setup-rclone
        with:
          access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
          secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
          endpoint: https://projects.pawsey.org.au
          bucket: ${{ vars.ACACIA_BUCKETNAME }}
          destination_path: ""  # Not used in upload mode
          upload_mode: 'true'
          upload_file: ${{ steps.save_container.outputs.archive_file }}
          upload_file_type: 'archive'

      - name: Load Singularity module and generate SIF file
        id: build_sif
        run: |
          # Get variables
          archive_file="${{ steps.save_container.outputs.archive_file }}"
          image_name="${{ steps.build_container.outputs.image_name }}"
          version="${{ needs.PREPARE-job.outputs.version }}"

          # Define SIF output file: name-variant_version.sif
          # image_name already includes variant suffix
          sif_file="${image_name}_${version}.sif"
          
          echo "Loading Singularity module and generating SIF file..."
          echo "Source: docker-archive://$archive_file"
          echo "Output: $sif_file"
          
          # Load Singularity module
          echo "Loading Singularity module..."
          if module load singularity/4.1.0; then
            echo "âœ“ Singularity module loaded successfully"
          else
            echo "âœ— Failed to load Singularity module"
            exit 1
          fi
          
          # Verify Singularity is available
          singularity --version
          
          # Build SIF file from Docker archive using Singularity
          echo "Building SIF file from Docker archive..."
          CORES=$(nproc)
          echo "Detected $CORES CPU cores for optimization"
          
          # Set environment variables for mksquashfs optimization
          export MKSQUASHFS_PROCESSORS=$CORES
          export MKSQUASHFS_MEM="80%"
          export MKSQUASHFS_COMP="zstd"
          export MKSQUASHFS_COMP_OPTS="-Xcompression-level 3"
          
          echo "Setting mksquashfs optimization via environment variables"
          
          # Singularity build with environment-based optimization
          if singularity build \
            --force \
            "$sif_file" "docker-archive://$archive_file"; then
            if [ -f "$sif_file" ]; then
              file_size=$(ls -lh "$sif_file" | awk '{print $5}')
              echo "âœ“ SIF file generated successfully: $sif_file (Size: $file_size)"
              echo "[SINGULARITY OPTIMIZATION]:"
              echo "  - Processors: $CORES cores"
              echo "  - Memory: 80% allocation"
              echo "  - Compression: zstd level 3"
              echo "  - Method: Environment variables"
            else
              echo "âœ— SIF file generation failed - file not found"
              exit 1
            fi
          else
            echo "âœ— Failed to generate SIF file"
            exit 1
          fi
          
          # Set outputs
          echo "sif_file=$sif_file" >> $GITHUB_OUTPUT
          echo "sif_path=${PWD}/$sif_file" >> $GITHUB_OUTPUT

      - name: Upload SIF file to S3 storage
        id: s3_sif_upload
        uses: ./.github/actions/setup-rclone
        with:
          access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
          secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
          endpoint: https://projects.pawsey.org.au
          bucket: ${{ vars.ACACIA_SIF_BUCKETNAME }}
          destination_path: ""  # Not used in upload mode
          upload_mode: 'true'
          upload_file: ${{ steps.build_sif.outputs.sif_file }}
          upload_file_type: 'sif'

  SCAN-AND-REPORT-job:
    needs: [BUILD-job, PREPARE-job]
    runs-on: setonix-podman02
    if: needs.PREPARE-job.outputs.proceed_valid == 'true' && needs.PREPARE-job.outputs.noscan != 'true'
    strategy:
      matrix: ${{ fromJson(needs.PREPARE-job.outputs.build_matrix) }}
      fail-fast: false
    env:
      IMAGE_NAME: ${{ needs.BUILD-job.outputs.image_name }}
      VERSION: ${{ needs.PREPARE-job.outputs.version }}
      REPORT_DIR: ./trivy-reports
    steps:
    - name: Display scan environment
      run: |
          echo "Hostname: $(hostname)"
          echo "Scanning: ${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
          echo "No Scan Flag: ${{ needs.PREPARE-job.outputs.noscan }}"
          echo "Variant #${{ matrix.index }}"

    - name: Download archive from S3
      id: locate
      uses: ./.github/actions/setup-rclone
      with:
        access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
        secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
        endpoint: https://projects.pawsey.org.au
        bucket: ${{ vars.ACACIA_BUCKETNAME }}
        destination_path: ${{ env.IMAGE_NAME }}_${{ env.VERSION }}.tar
        download_mode: true
        dockerfile_name: ${{ env.IMAGE_NAME }}
        version: ${{ env.VERSION }}
        load_to_podman: false

    - name: Initialize scan workspace
      run: |
        mkdir -p "${REPORT_DIR}"
        echo "Report directory created: ${REPORT_DIR}"

    # Generate JSON report first
    - name: Run vulnerability scan (JSON)
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: image
        input: ./${{ steps.locate.outputs.archive_name }}
        format: json
        output: ${{ env.REPORT_DIR }}/scan-results.json
        severity: CRITICAL,HIGH,MEDIUM,LOW,UNKNOWN
        ignore-unfixed: true
        vuln-type: os,library
        exit-code: '0'
        hide-progress: true
        cache: true
      env:
        TRIVY_SKIP_DB_UPDATE: false
        TRIVY_SKIP_JAVA_DB_UPDATE: false

    # Process JSON to create readable summary
    - name: Process scan results to summary
      run: |
        python3 -c "
        import json
        import sys
        import os
        
        json_file = '${REPORT_DIR}/scan-results.json'
        output_file = '${REPORT_DIR}/summary.md'
        
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
            
            # Initialize counters
            counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0, 'UNKNOWN': 0}
            vulnerabilities = []
            
            # Process results
            if 'Results' in data and data['Results']:
                for result in data['Results']:
                    if 'Vulnerabilities' in result and result['Vulnerabilities']:
                        for vuln in result['Vulnerabilities']:
                            severity = vuln.get('Severity', 'UNKNOWN')
                            if severity in counts:
                                counts[severity] += 1
                            vulnerabilities.append(vuln)
            
            # Generate summary
            with open(output_file, 'w') as f:
                artifact_name = data.get('ArtifactName', 'Unknown')
                f.write(f'## Trivy Scan Summary â€” {artifact_name}\n\n')
                f.write(f'**Target:** {artifact_name}\n')
                f.write(f'**Total Vulnerabilities:** {sum(counts.values())}\n\n')
                
                f.write('### Severity Counts\n')
                for severity, count in counts.items():
                    if count > 0:
                        f.write(f'- **{severity}:** {count}\n')
                    else:
                        f.write(f'- {severity}: {count}\n')
                f.write('\n')
                
                # Show critical and high details
                critical_high = [v for v in vulnerabilities if v.get('Severity') in ['CRITICAL', 'HIGH']]
                if critical_high:
                    f.write('### Critical & High Severity Vulnerabilities\n\n')
                    f.write('| Severity | CVE ID | Package | Installed | Fixed |\n')
                    f.write('|----------|--------|---------|-----------|-------|\n')
                    for vuln in critical_high[:15]:  # Limit to first 15
                        severity = vuln.get('Severity', 'N/A')
                        cve_id = vuln.get('VulnerabilityID', 'N/A')
                        pkg = vuln.get('PkgName', 'N/A')
                        installed = vuln.get('InstalledVersion', 'N/A')
                        fixed = vuln.get('FixedVersion', 'N/A') or 'âŒ'
                        f.write(f'| {severity} | {cve_id} | {pkg} | {installed} | {fixed} |\n')
                    
                    if len(critical_high) > 15:
                        f.write(f'\n*... and {len(critical_high) - 15} more critical/high vulnerabilities.*\n')
                elif sum(counts.values()) > 0:
                    f.write('### Good News! ðŸŽ‰\n\n')
                    f.write('No CRITICAL or HIGH severity vulnerabilities found.\n')
                    if counts['MEDIUM'] > 0:
                        f.write(f'Only {counts[\"MEDIUM\"]} MEDIUM severity issues detected.\n')
                else:
                    f.write('### Excellent! âœ…\n\n')
                    f.write('No vulnerabilities found in this image.\n')
            
            print(f'Successfully generated summary: {output_file}')
            
        except Exception as e:
            with open(output_file, 'w') as f:
                f.write(f'### âŒ Error Processing Scan Results\n\n')
                f.write(f'**Error:** {str(e)}\n\n')
                f.write(f'**JSON file:** {json_file}\n')
                f.write(f'**File exists:** {os.path.exists(json_file)}\n')
            print(f'Error: {e}', file=sys.stderr)
        "

    - name: Debug scan output
      run: |
        echo "=== Trivy output file exists? ==="
        ls -la "${REPORT_DIR}/summary.md" || echo "Summary file not found"
        echo ""
        echo "=== Trivy output content ==="
        cat "${REPORT_DIR}/summary.md" || echo "Cannot read summary file"
        echo ""
        echo "=== Report directory contents ==="
        ls -la "${REPORT_DIR}/" || echo "Report directory not found"

    - name: Publish scan report to workflow summary
      run: |
        {
          echo "## Trivy Scan Report for \`${{ env.IMAGE_NAME }}\`"
          echo ""
          echo "- **Scan target**: \`${{ steps.locate.outputs.archive_name }}\`"
          echo "- **Archive source**: \`${{ steps.locate.outputs.archive_path }}\`"
          echo "- **Version**: \`${{ env.VERSION }}\`"
          echo "- **Correlation ID**: \`${{ needs.PREPARE-job.outputs.correlation_id }}\`"
          echo ""
          
          # Check if summary file exists and has content
          if [ -f "${REPORT_DIR}/summary.md" ] && [ -s "${REPORT_DIR}/summary.md" ]; then
            echo "### Scan Results"
            cat "${REPORT_DIR}/summary.md"
          else
            echo "### âš ï¸ Scan Results"
            echo ""
            echo "**Status:** Summary file not generated or empty"
            echo ""
            echo "**Possible causes:**"
            echo "- Trivy template processing failed"
            echo "- Archive file format issue"
            echo "- Trivy action configuration problem"
            echo ""
            echo "Check the debug steps above for more details."
          fi
        } >> "$GITHUB_STEP_SUMMARY"

    # Generate SARIF report for GitHub Security
    - name: Generate security report (SARIF)
      uses: aquasecurity/trivy-action@master
      if: always()
      with:
        scan-type: image
        input: ./${{ steps.locate.outputs.archive_name }}
        format: sarif
        output: ${{ env.REPORT_DIR }}/trivy-results.sarif
        severity: CRITICAL,HIGH,MEDIUM
        ignore-unfixed: true
        vuln-type: os,library
        exit-code: '0'
        hide-progress: true
        cache: true
      env:
        TRIVY_SKIP_DB_UPDATE: true
        TRIVY_SKIP_JAVA_DB_UPDATE: true

    - name: Archive scan reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: trivy-reports-${{ env.IMAGE_NAME }}-${{ env.VERSION }}-variant-${{ matrix.index }}
        path: ${{ env.REPORT_DIR }}/
        retention-days: 30

  PUSH-PRIV-job:
    needs: [BUILD-job, PREPARE-job]
    runs-on: setonix-podman02
    if: needs.PREPARE-job.outputs.proceed_valid == 'true'
    strategy:
      matrix: ${{ fromJson(needs.PREPARE-job.outputs.build_matrix) }}
      fail-fast: false
    env:
      IMAGE_NAME: ${{ needs.BUILD-job.outputs.image_name }}
      VERSION: ${{ needs.PREPARE-job.outputs.version }}
      BUCKET: ${{ vars.ACACIA_BUCKETNAME }}
    steps:
    - name: Display registry environment
      run: |
        echo "Hostname: $(hostname)"
        echo "Pushing: ${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
        echo "Variant #${{ matrix.index }}"

    - name: Configure podman environment
      run: |
        echo "Setting up container environment variables for push..."
        
        # Export environment variables (same as BUILD-job)
        export XDG_DATA_HOME=/container/${USER}/data
        export XDG_RUNTIME_DIR=/container/${USER}/runtime
        export TMPDIR=/container/${USER}/tmp/
        
        # Create required directories
        mkdir -p ${XDG_DATA_HOME}
        mkdir -p ${XDG_RUNTIME_DIR}
        mkdir -p ${TMPDIR}
        
        echo "Push environment setup completed:"
        echo "XDG_DATA_HOME: ${XDG_DATA_HOME}"
        echo "XDG_RUNTIME_DIR: ${XDG_RUNTIME_DIR}"
        echo "TMPDIR: ${TMPDIR}"
        
        # Set environment variables for subsequent steps
        echo "XDG_DATA_HOME=${XDG_DATA_HOME}" >> $GITHUB_ENV
        echo "XDG_RUNTIME_DIR=${XDG_RUNTIME_DIR}" >> $GITHUB_ENV
        echo "TMPDIR=${TMPDIR}" >> $GITHUB_ENV

    - name: Download archive from S3
      id: locate_archive
      uses: ./.github/actions/setup-rclone
      with:
        access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
        secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
        endpoint: https://projects.pawsey.org.au
        bucket: ${{ env.BUCKET }}
        destination_path: ${{ env.IMAGE_NAME }}_${{ env.VERSION }}.tar
        download_mode: true
        dockerfile_name: ${{ env.IMAGE_NAME }}
        version: ${{ env.VERSION }}
        load_to_podman: false

    - name: Push to Setonix private registry
      if: needs.PREPARE-job.outputs.setonixreg_available == 'true'
      continue-on-error: true
      run: |
        set +e  # Don't exit on errors to allow independent execution
        echo "=========================================="
        echo " Setonix Registry Push Process"
        echo "=========================================="
        
        # Load image from archive first
        echo "ðŸ“¦ Loading image from archive..."
        archive_file="${{ steps.locate_archive.outputs.archive_name }}"
        if podman load -i "$archive_file"; then
          echo "âœ“ Image loaded successfully from archive"
        else
          echo "âœ— Failed to load image from archive"
          exit 1
        fi
        
        # Login to Setonix Registry
        echo "ðŸ” Logging into Setonix Registry..."
        if podman login https://setonix-registry.pawsey.org.au -u "${{ vars.SETONIXREG_USERNAME }}" -p "${{ secrets.SETONIXREG_PASS }}"; then
          echo "âœ“ Setonix Registry login successful"
        else
          echo "âœ— Setonix Registry login failed"
          exit 1
        fi
        
        # Get private targets from manifest and use the first one as username
        private_targets='${{ needs.PREPARE-job.outputs.private_targets }}'
        private_username=$(echo "$private_targets" | jq -r '.[0] // empty')
        
        if [ -z "$private_username" ] || [ "$private_username" = "null" ]; then
          echo "Error: No private targets found in manifest"
          exit 1
        fi
        
        # Tag and push (IMAGE_NAME already includes variant suffix from BUILD-job)
        image_tag="${IMAGE_NAME}:${VERSION}"
        setonix_tag="setonix-registry.pawsey.org.au/${private_username}/${IMAGE_NAME}:${VERSION}"
        
        echo ""
        echo "ðŸ·ï¸  Tagging image for Setonix Registry:"
        echo "   Source: $image_tag"
        echo "   Target: $setonix_tag"
        
        if podman tag "$image_tag" "$setonix_tag"; then
          echo "âœ“ Image tagged successfully"
        else
          echo "âœ— Image tagging failed"
          exit 1
        fi
        
        echo ""
        echo "ðŸ“¤ Pushing to Setonix Registry..."
        if podman push "$setonix_tag"; then
          echo "âœ… Successfully pushed to Setonix Registry: $setonix_tag"
        else
          echo "âŒ Failed to push to Setonix Registry"
          exit 1
        fi
        
        # Cleanup local tagged image
        echo ""
        echo "ðŸ§¹ Cleaning up local Setonix tagged image..."
        podman rmi "$setonix_tag" 2>/dev/null || echo "  (Setonix tag already removed or not found)"
        podman rmi "$image_tag" 2>/dev/null || echo "  (Base image already removed or not found)"

  PUSH-PUBLIC-job:
    needs: [BUILD-job, PREPARE-job, PUSH-PRIV-job]
    runs-on: setonix-podman02
    if: needs.PREPARE-job.outputs.proceed_valid == 'true'
    strategy:
      matrix: ${{ fromJson(needs.PREPARE-job.outputs.build_matrix) }}
      fail-fast: false
    # Environment selection based on devmode flag and targets:
    # - If devmode=true OR targets is empty: Use 'devmode_skip_approval' environment (no manual approval required)
    # - If devmode=false AND targets has values: Use 'manual_approval' environment (requires manual approval)
    environment:
      name: ${{ (needs.PREPARE-job.outputs.devmode == 'true' || needs.PREPARE-job.outputs.targets == '[]') && 'devmode_skip_approval' || 'manual_approval' }}
    env:
      IMAGE_NAME: ${{ needs.BUILD-job.outputs.image_name }}
      VERSION: ${{ needs.PREPARE-job.outputs.version }}
      TARGETS: ${{ needs.PREPARE-job.outputs.targets }}
    steps:
    - name: Display public registry push plan
      run: |
        echo "Hostname: $(hostname)"
        echo "Image: ${IMAGE_NAME}:${VERSION}"
        echo "Variant #${{ matrix.index }}"
        echo "Configured Targets: $TARGETS"
        echo ""
        echo "=== Public Registry Push Plan ==="
        echo "Registry credentials were checked in PREPARE-job:"
        echo ""

        # Parse targets from manifest
        targets_array=$(echo '${{ needs.PREPARE-job.outputs.targets }}' | jq -r '.[]')

        # Check each target from manifest against available credentials
        echo "$targets_array" | while read -r target; do
          case "$target" in
            "quay.io")
              if [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ]; then
                echo "[âœ“] Quay.io: Will push to quay.io/pawsey/${IMAGE_NAME}:${VERSION}"
              else
                echo "[skip] Quay.io: Requested in manifest but credentials not available"
              fi
              ;;
            "setonix-registry")
              if [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ]; then
                echo "[âœ“] Setonix Public Registry: Will push to setonix-registry.pawsey.org.au/pawsey/${IMAGE_NAME}:${VERSION}"
              else
                echo "[skip] Setonix Registry: Requested in manifest but credentials not available"
              fi
              ;;
            *)
              echo "[skip] Unknown target: $target"
              ;;
          esac
        done
        echo ""

    - name: Configure podman environment
      if: needs.PREPARE-job.outputs.quayio_available == 'true' || needs.PREPARE-job.outputs.setonixreg_available == 'true'
      run: |
        echo "Setting up container environment variables for public push..."
        
        # Export environment variables (same as BUILD-job)
        export XDG_DATA_HOME=/container/${USER}/data
        export XDG_RUNTIME_DIR=/container/${USER}/runtime
        export TMPDIR=/container/${USER}/tmp/
        
        # Create required directories
        mkdir -p ${XDG_DATA_HOME}
        mkdir -p ${XDG_RUNTIME_DIR}
        mkdir -p ${TMPDIR}
        
        echo "Public push environment setup completed:"
        echo "XDG_DATA_HOME: ${XDG_DATA_HOME}"
        echo "XDG_RUNTIME_DIR: ${XDG_RUNTIME_DIR}"
        echo "TMPDIR: ${TMPDIR}"
        
        # Set environment variables for subsequent steps
        echo "XDG_DATA_HOME=${XDG_DATA_HOME}" >> $GITHUB_ENV
        echo "XDG_RUNTIME_DIR=${XDG_RUNTIME_DIR}" >> $GITHUB_ENV
        echo "TMPDIR=${TMPDIR}" >> $GITHUB_ENV

    - name: Download archive and load to podman
      id: locate_and_load
      if: needs.PREPARE-job.outputs.quayio_available == 'true' || needs.PREPARE-job.outputs.setonixreg_available == 'true'
      uses: ./.github/actions/setup-rclone
      with:
        access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
        secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
        endpoint: https://projects.pawsey.org.au
        bucket: ${{ vars.ACACIA_BUCKETNAME }}
        destination_path: ${{ env.IMAGE_NAME }}_${{ env.VERSION }}.tar
        download_mode: true
        dockerfile_name: ${{ env.IMAGE_NAME }}
        version: ${{ env.VERSION }}
        load_to_podman: true

    - name: Initialize Docker configuration
      if: needs.PREPARE-job.outputs.quayio_available == 'true' || needs.PREPARE-job.outputs.setonixreg_available == 'true'
      run: |
        mkdir -p ~/.docker
        echo "Created Docker config directory: ~/.docker"


    # ============================================
    # Quay.io Push (Only if in targets)
    # ============================================
    - name: Push to Quay.io public registry
      if: needs.PREPARE-job.outputs.quayio_available == 'true' && contains(needs.PREPARE-job.outputs.targets, 'quay.io')
      continue-on-error: true
      run: |
        set +e  # Don't exit on errors to allow independent execution
        echo "=========================================="
        echo " Quay.io Push Process"
        echo "=========================================="
        
        # Login to Quay.io
        echo "ðŸ” Logging into Quay.io..."
        if podman login quay.io -u "${{ vars.QUAYIO_USERNAME }}" -p "${{ secrets.QUAYIO_TOKEN }}"; then
          echo "âœ“ Quay.io login successful"
        else
          echo "âœ— Quay.io login failed"
          exit 1
        fi
        
        # Tag and push (IMAGE_NAME already includes variant suffix from BUILD-job)
        image_tag="${{ steps.locate_and_load.outputs.image_tag }}"
        quayio_tag="quay.io/pawsey/${IMAGE_NAME}:${VERSION}"
        
        echo ""
        echo "ðŸ·ï¸  Tagging image for Quay.io:"
        echo "   Source: $image_tag"
        echo "   Target: $quayio_tag"
        
        if podman tag "$image_tag" "$quayio_tag"; then
          echo "âœ“ Image tagged successfully"
        else
          echo "âœ— Image tagging failed"
          exit 1
        fi
        
        echo ""
        echo "ðŸ“¤ Pushing to Quay.io..."
        if podman push "$quayio_tag"; then
          echo "âœ… Successfully pushed to Quay.io: $quayio_tag"
          
          # Ensure repository is set to public for SHPC deployment
          echo "Setting repository visibility to public..."
          visibility_response=$(curl -s -X POST \
            -H "Authorization: Bearer ${{ secrets.QUAYIO_TOKEN }}" \
            -H "Content-Type: application/json" \
            -d '{"visibility": "public"}' \
            "https://quay.io/api/v1/repository/pawsey/${IMAGE_NAME}/changevisibility")
          
          if echo "$visibility_response" | jq -e '.success' > /dev/null 2>&1; then
            echo "âœ“ Repository visibility set to public"
          else
            echo "â„¹ï¸  Repository visibility API call completed (status unknown)"
          fi
        else
          echo "âŒ Failed to push to Quay.io"
          exit 1
        fi

    # ============================================
    # Setonix Public Registry Push (Only if in targets)
    # ============================================
    - name: Push to Setonix public registry
      if: needs.PREPARE-job.outputs.setonixreg_available == 'true' && contains(needs.PREPARE-job.outputs.targets, 'setonix-registry')
      continue-on-error: true
      run: |
        set +e  # Don't exit on errors to allow independent execution
        echo "=========================================="
        echo " Setonix Public Registry Push Process"
        echo "=========================================="
        
        # Login to Setonix Registry
        echo "ðŸ” Logging into Setonix Registry..."
        if podman login https://setonix-registry.pawsey.org.au -u "${{ vars.SETONIXREG_USERNAME }}" -p "${{ secrets.SETONIXREG_PASS }}"; then
          echo "âœ“ Setonix Registry login successful"
        else
          echo "âœ— Setonix Registry login failed"
          exit 1
        fi
        
        # Tag and push to public channel (IMAGE_NAME already includes variant suffix from BUILD-job)
        image_tag="${{ steps.locate_and_load.outputs.image_tag }}"
        setonix_public_tag="setonix-registry.pawsey.org.au/pawsey/${IMAGE_NAME}:${VERSION}"
        
        echo ""
        echo "ðŸ·ï¸  Tagging image for Setonix Public Registry:"
        echo "   Source: $image_tag"
        echo "   Target: $setonix_public_tag"
        
        if podman tag "$image_tag" "$setonix_public_tag"; then
          echo "âœ“ Image tagged successfully"
        else
          echo "âœ— Image tagging failed"
          exit 1
        fi
        
        echo ""
        echo "ðŸ“¤ Pushing to Setonix Public Registry..."
        if podman push "$setonix_public_tag"; then
          echo "âœ… Successfully pushed to Setonix Public Registry: $setonix_public_tag"
        else
          echo "âŒ Failed to push to Setonix Public Registry"
          exit 1
        fi

    - name: Clean up podman images
      if: always() && (needs.PREPARE-job.outputs.quayio_available == 'true' || needs.PREPARE-job.outputs.setonixreg_available == 'true')
      run: |
        echo "ðŸ§¹ Cleaning up local images..."
        image_tag="${{ steps.locate_and_load.outputs.image_tag }}"
        
        # Remove original image
        echo "Removing base image: $image_tag"
        podman rmi "$image_tag" 2>/dev/null || echo "  (Base image already removed or not found)"
        
        # Remove tagged images based on targets (IMAGE_NAME already includes variant suffix from BUILD-job)
        if [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ] && echo '${{ needs.PREPARE-job.outputs.targets }}' | jq -e 'contains(["quay.io"])' > /dev/null; then
          quayio_tag="quay.io/pawsey/${IMAGE_NAME}:${VERSION}"
          echo "Removing Quay.io tag: $quayio_tag"
          podman rmi "$quayio_tag" 2>/dev/null || echo "  (Quay.io tag already removed or not found)"
        fi

        if [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ] && echo '${{ needs.PREPARE-job.outputs.targets }}' | jq -e 'contains(["setonix-registry"])' > /dev/null; then
          setonix_public_tag="setonix-registry.pawsey.org.au/pawsey/${IMAGE_NAME}:${VERSION}"
          echo "Removing Setonix Public tag: $setonix_public_tag"
          podman rmi "$setonix_public_tag" 2>/dev/null || echo "  (Setonix Public tag already removed or not found)"
        fi
        
        echo "âœ… Local image cleanup completed"

  DEPLOY-job:
    needs: [BUILD-job, PREPARE-job, PUSH-PUBLIC-job]
    runs-on: setonix-podman02
    if: needs.PREPARE-job.outputs.proceed_valid == 'true' && needs.PREPARE-job.outputs.shpc == 'true' && (needs.PREPARE-job.outputs.quayio_available == 'true' && contains(needs.PREPARE-job.outputs.targets, 'quay.io'))
    strategy:
      matrix: ${{ fromJson(needs.PREPARE-job.outputs.build_matrix) }}
      fail-fast: false
    env:
      IMAGE_NAME: ${{ needs.BUILD-job.outputs.image_name }}
      VERSION: ${{ needs.PREPARE-job.outputs.version }}
    steps:
      - name: Display deployment environment
        run: |
          echo "Hostname: $(hostname)"
          echo "Starting SHPC deployment for ${IMAGE_NAME}:${VERSION}"
          echo "Variant #${{ matrix.index }}"
          echo "Configured targets: ${{ needs.PREPARE-job.outputs.targets }}"
          echo ""
          echo "Available public registries for SHPC:"
          if [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ] && echo '${{ needs.PREPARE-job.outputs.targets }}' | jq -e 'contains(["quay.io"])' > /dev/null; then
            echo "â€¢ Quay.io: quay.io/pawsey/${IMAGE_NAME}:${VERSION}"
          fi

      - name: Load SHPC module and setup environment
        id: shpc_setup
        run: |
          set -euo pipefail
          echo "Loading SHPC module..."
          if module load shpc/0.1.32; then
            echo "âœ“ SHPC module loaded successfully"
            shpc --version
          else
            echo "âœ— Failed to load SHPC module"
            exit 1
          fi
          
          # Set SHPC registry path
          SHPC_REGISTRY="/software/setonix/2025.08/pawsey/software/shpc/pawsey_registry"
          echo "SHPC_REGISTRY=$SHPC_REGISTRY" >> $GITHUB_ENV
          echo "SHPC registry path: $SHPC_REGISTRY"

      - name: Determine deployment target and get SHA256 digest
        id: get_image_info
        run: |
          set -euo pipefail

          # Use Quay.io for deployment (IMAGE_NAME already includes variant suffix from BUILD-job)
          if [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ] && echo '${{ needs.PREPARE-job.outputs.targets }}' | jq -e 'contains(["quay.io"])' > /dev/null; then
            full_image="quay.io/pawsey/${IMAGE_NAME}:${VERSION}"
            registry_url="https://quay.io/v2"
            api_path="pawsey/${IMAGE_NAME}"
            registry_type="quay.io"
          else
            echo "Error: Quay.io registry not available for deployment"
            echo "Quay.io must be available and in targets for SHPC deployment"
            exit 1
          fi

          echo "Deploying image: $full_image"
          echo "Registry API: $registry_url"
          echo "API path: $api_path"

          # Get manifest and extract digest
          echo "Fetching manifest for tag: ${VERSION}"

          digest=$(curl -s -H "Accept: application/vnd.docker.distribution.manifest.v2+json" \
            "$registry_url/$api_path/manifests/${VERSION}" \
            | jq -r '.config.digest // empty')

          if [ -z "$digest" ] || [ "$digest" = "null" ]; then
            echo "Warning: Could not get digest, using placeholder"
            digest="sha256:placeholder_digest_for_${VERSION}"
          fi
          
          echo "SHA256 digest: $digest"
          
          # Set outputs
          echo "full_image=$full_image" >> $GITHUB_OUTPUT
          echo "registry_type=$registry_type" >> $GITHUB_OUTPUT
          echo "digest=$digest" >> $GITHUB_OUTPUT

      - name: Create SHPC container registry entry
        run: |
          set -euo pipefail
          
          full_image="${{ steps.get_image_info.outputs.full_image }}"
          registry_type="${{ steps.get_image_info.outputs.registry_type }}"
          digest="${{ steps.get_image_info.outputs.digest }}"
          
          # Create registry directory structure based on the deployed image
          # IMAGE_NAME already includes variant suffix from BUILD-job
          shpc_path="${SHPC_REGISTRY}/quay.io/pawsey/${IMAGE_NAME}"

          echo "Creating SHPC registry entry at: $shpc_path"

          # Create container.yaml content
          container_yaml=$(cat <<EOF
          docker: $full_image

          latest:
            "${VERSION}": "$digest"
          tags:
            "${VERSION}": "$digest"
          
          maintainer: "@image-manager-ci"
          
          description: "Container for ${IMAGE_NAME} version ${VERSION} - deployed via Image Manager CI/CD"
          url: "https://github.com/${GITHUB_REPOSITORY}"
          
          # Image Manager metadata
          image_manager:
            main: "${{ needs.PREPARE-job.outputs.main }}"
            feature: "${{ needs.PREPARE-job.outputs.feature }}"
            platform: "${{ needs.PREPARE-job.outputs.platform }}"
            variant_index: ${{ matrix.index }}
            image_name: "${IMAGE_NAME}"
            correlation_id: "${{ needs.PREPARE-job.outputs.correlation_id }}"
            branch: "${{ github.ref_name }}"
            deployed_at: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          EOF
          )
          
          echo "Container YAML content:"
          echo "$container_yaml"
          
          # Verify SHPC configuration before writing
          echo "Verifying SHPC configuration..."
          module load shpc/0.1.32
          if shpc config get registry | grep -q pawsey_registry; then
            echo "âœ“ SHPC registry is properly configured"
          else
            echo "Warning: SHPC registry may not be properly configured"
          fi
          
          # Write container YAML to temporary file
          temp_file="/tmp/container_${RANDOM}.yaml"
          echo "$container_yaml" > "$temp_file"
          echo "Container YAML written to temporary file: $temp_file"
          
          # Switch to spack user to create registry entry
          echo "Switching to spack user to write to registry..."
          sudo su - spack << EOF
          set -euo pipefail
          echo "Now running as spack user"
          mkdir -p '$shpc_path'
          cp '$temp_file' '$shpc_path/container.yaml'
          echo 'âœ“ SHPC registry entry created successfully'
          ls -la '$shpc_path/'
          cat '$shpc_path/container.yaml'
          EOF
          
          # Clean up temporary file
          rm -f "$temp_file"
          echo "Temporary file cleaned up"
          
          echo "âœ… SHPC deployment completed"
          echo "Registry path: $shpc_path"
          echo "Image: $full_image"
          echo "Version: ${VERSION}"
          echo "Variant #${{ matrix.index }}"
          echo "Digest: $digest"
          echo "Correlation ID: ${{ needs.PREPARE-job.outputs.correlation_id }}"

  SUMMARY-job:
    needs: [BUILD-job, PREPARE-job, PUSH-PRIV-job, PUSH-PUBLIC-job, DEPLOY-job]
    runs-on: ubuntu-latest
    if: always() && needs.PREPARE-job.outputs.proceed_valid == 'true'
    env:
      MAIN: ${{ needs.PREPARE-job.outputs.main }}
      FEATURE: ${{ needs.PREPARE-job.outputs.feature }}
      VERSION: ${{ needs.PREPARE-job.outputs.version }}
      PLATFORM: ${{ needs.PREPARE-job.outputs.platform }}
      CORRELATION_ID: ${{ needs.PREPARE-job.outputs.correlation_id }}
      VARIANT_COUNT: ${{ needs.PREPARE-job.outputs.variant_count }}
      HAS_TEMPLATE: ${{ needs.PREPARE-job.outputs.has_template }}
    steps:
      - name: Summary - Header
        run: |
          IMAGE_NAME="${MAIN}-${FEATURE}"

          {
            echo "# ðŸš€ Image Manager CI/CD Summary"
            echo ""
            echo "**Image:** \`${IMAGE_NAME}:${VERSION}\`"
            echo "**Main Software:** \`${{ env.MAIN }}\`"
            echo "**Feature:** \`${{ env.FEATURE }}\`"
            echo "**Platform:** \`${{ env.PLATFORM }}\`"
            echo "**Build Status:** âœ… Completed"
            echo "**Correlation ID:** \`${{ env.CORRELATION_ID }}\`"
            echo "**Branch:** \`${{ github.ref_name }}\`"
            echo "**Timestamp:** $(date '+%Y-%m-%d %H:%M:%S UTC')"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Summary - Variant Information
        if: env.HAS_TEMPLATE == 'true'
        run: |
          {
            echo "## ðŸ”€ Multi-Variant Build"
            echo ""
            echo "**Variant Count:** ${{ env.VARIANT_COUNT }}"
            echo ""
            echo "Matrix configuration generated ${{ env.VARIANT_COUNT }} build variant(s) based on template parameters."
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Summary - Archive Storage
        run: |
          IMAGE_NAME="${MAIN}-${FEATURE}"

          {
            echo "## ðŸ“¦ Archive Storage"
            echo ""

            if [ "${{ env.HAS_TEMPLATE }}" = "true" ]; then
              echo "> **Note:** This build produced ${{ env.VARIANT_COUNT }} variant(s). Each variant has separate Docker archive and SIF files."
              echo ""
              echo "**Docker Archives** (\`s3://${{ vars.ACACIA_BUCKETNAME }}/\`):"

              # Parse matrix and compute variant_suffix for each variant (lowercase for container compatibility)
              matrix_json='${{ needs.PREPARE-job.outputs.build_matrix }}'
              echo "$matrix_json" | jq -r '.include[] |
                .values |
                to_entries |
                map("-" + (.key | ascii_downcase) + "-" + (.value | ascii_downcase)) |
                join("") as $suffix |
                "- `'${IMAGE_NAME}'" + $suffix + "_${VERSION}.tar`"'

              echo ""
              echo "**Singularity SIF Files** (\`s3://${{ vars.ACACIA_SIF_BUCKETNAME }}/\`):"
              echo "$matrix_json" | jq -r '.include[] |
                .values |
                to_entries |
                map("-" + (.key | ascii_downcase) + "-" + (.value | ascii_downcase)) |
                join("") as $suffix |
                "- `'${IMAGE_NAME}'" + $suffix + "_${VERSION}.sif`"'
            else
              echo "| Location | Address | Status |"
              echo "|----------|---------|--------|"

              # S3 Docker Archive Storage
              if [ "${{ needs.BUILD-job.result }}" = "success" ]; then
                echo "| S3 Docker Archive | \`s3://${{ vars.ACACIA_BUCKETNAME }}/${IMAGE_NAME}_${VERSION}.tar\` | âœ… Uploaded |"
              else
                echo "| S3 Docker Archive | \`s3://${{ vars.ACACIA_BUCKETNAME }}/${IMAGE_NAME}_${VERSION}.tar\` | âŒ Failed |"
              fi

              # S3 Singularity SIF Storage
              if [ "${{ needs.BUILD-job.result }}" = "success" ]; then
                echo "| S3 Singularity SIF | \`s3://${{ vars.ACACIA_SIF_BUCKETNAME }}/${IMAGE_NAME}_${VERSION}.sif\` | âœ… Uploaded |"
              else
                echo "| S3 Singularity SIF | \`s3://${{ vars.ACACIA_SIF_BUCKETNAME }}/${IMAGE_NAME}_${VERSION}.sif\` | âŒ Failed |"
              fi
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Summary - Registry Deployments (With Template)
        if: env.HAS_TEMPLATE == 'true'
        run: |
          IMAGE_NAME="${MAIN}-${FEATURE}"

          {
            echo "## ðŸ—ï¸ Container Registry Deployments"
            echo ""
            echo "> **Note:** Each of the ${{ env.VARIANT_COUNT }} variant(s) has been pushed to the configured registries."
            echo ""

            # Parse configured targets
            targets='${{ needs.PREPARE-job.outputs.targets }}'
            private_targets='${{ needs.PREPARE-job.outputs.private_targets }}'
            private_username=$(echo "$private_targets" | jq -r '.[0] // "unknown"')
            matrix_json='${{ needs.PREPARE-job.outputs.build_matrix }}'

            # Setonix Private Registry
            if [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ]; then
              echo "### Setonix Private Registry"
              echo ""
              echo "$matrix_json" | jq -r '.include[] |
                .values |
                to_entries |
                map("-" + (.key | ascii_downcase) + "-" + (.value | ascii_downcase)) |
                join("") as $suffix |
                "- \`setonix-registry.pawsey.org.au/'"${private_username}"'/'"${IMAGE_NAME}"'" + $suffix + ":'"${VERSION}"'\`"'
              echo ""
            fi

            # Quay.io
            if echo "$targets" | jq -e 'contains(["quay.io"])' > /dev/null 2>&1 && [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ]; then
              echo "### Quay.io Public Registry"
              echo ""
              echo "$matrix_json" | jq -r '.include[] |
                .values |
                to_entries |
                map("-" + (.key | ascii_downcase) + "-" + (.value | ascii_downcase)) |
                join("") as $suffix |
                "- \`quay.io/pawsey/'"${IMAGE_NAME}"'" + $suffix + ":'"${VERSION}"'\`"'
              echo ""
            fi

            # Setonix Public
            if echo "$targets" | jq -e 'contains(["setonix-registry"])' > /dev/null 2>&1 && [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ]; then
              echo "### Setonix Public Registry"
              echo ""
              echo "$matrix_json" | jq -r '.include[] |
                .values |
                to_entries |
                map("-" + (.key | ascii_downcase) + "-" + (.value | ascii_downcase)) |
                join("") as $suffix |
                "- \`setonix-registry.pawsey.org.au/pawsey/'"${IMAGE_NAME}"'" + $suffix + ":'"${VERSION}"'\`"'
              echo ""
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Summary - Registry Deployments (No Template)
        if: env.HAS_TEMPLATE != 'true'
        run: |
          IMAGE_NAME="${MAIN}-${FEATURE}"

          {
            echo "## ðŸ—ï¸ Container Registry Deployments"
            echo ""
            echo "| Registry | Address | Status |"
            echo "|----------|---------|--------|"

            # Parse configured targets
            targets='${{ needs.PREPARE-job.outputs.targets }}'

            # Setonix Private Registry (always attempted if credentials available)
            private_targets='${{ needs.PREPARE-job.outputs.private_targets }}'
            private_username=$(echo "$private_targets" | jq -r '.[0] // "unknown"')
            if [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ] && [ "${{ needs.PUSH-PRIV-job.result }}" = "success" ]; then
              echo "| Setonix Private | \`setonix-registry.pawsey.org.au/${private_username}/${IMAGE_NAME}:${VERSION}\` | âœ… Pushed |"
            elif [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ]; then
              echo "| Setonix Private | \`setonix-registry.pawsey.org.au/${private_username}/${IMAGE_NAME}:${VERSION}\` | âŒ Failed |"
            else
              echo "| Setonix Private | \`setonix-registry.pawsey.org.au/${private_username}/${IMAGE_NAME}:${VERSION}\` | â­ï¸ Skipped (No credentials) |"
            fi

            # Quay.io (only if in targets)
            if echo "$targets" | jq -e 'contains(["quay.io"])' > /dev/null 2>&1; then
              if [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ] && [ "${{ needs.PUSH-PUBLIC-job.result }}" = "success" ]; then
                echo "| Quay.io | \`quay.io/pawsey/${IMAGE_NAME}:${VERSION}\` | âœ… Pushed |"
              elif [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ]; then
                echo "| Quay.io | \`quay.io/pawsey/${IMAGE_NAME}:${VERSION}\` | âŒ Failed |"
              else
                echo "| Quay.io | \`quay.io/pawsey/${IMAGE_NAME}:${VERSION}\` | â­ï¸ Skipped (No credentials) |"
              fi
            else
              echo "| Quay.io | \`quay.io/pawsey/${IMAGE_NAME}:${VERSION}\` | â­ï¸ Not in targets |"
            fi

            # Setonix Public Registry (only if in targets)
            if echo "$targets" | jq -e 'contains(["setonix-registry"])' > /dev/null 2>&1; then
              if [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ] && [ "${{ needs.PUSH-PUBLIC-job.result }}" = "success" ]; then
                echo "| Setonix Public | \`setonix-registry.pawsey.org.au/pawsey/${IMAGE_NAME}:${VERSION}\` | âœ… Pushed |"
              elif [ "${{ needs.PREPARE-job.outputs.setonixreg_available }}" = "true" ]; then
                echo "| Setonix Public | \`setonix-registry.pawsey.org.au/pawsey/${IMAGE_NAME}:${VERSION}\` | âŒ Failed |"
              else
                echo "| Setonix Public | \`setonix-registry.pawsey.org.au/pawsey/${IMAGE_NAME}:${VERSION}\` | â­ï¸ Skipped (No credentials) |"
              fi
            else
              echo "| Setonix Public | \`setonix-registry.pawsey.org.au/pawsey/${IMAGE_NAME}:${VERSION}\` | â­ï¸ Not in targets |"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Summary - SHPC Deployment
        run: |
          IMAGE_NAME="${MAIN}-${FEATURE}"

          {
            echo ""
            echo "## ðŸš€ SHPC Container Deployment"
            echo ""

            # SHPC deployment status
            if [ "${{ needs.DEPLOY-job.result }}" = "success" ]; then
              # Use Quay.io for SHPC deployment
              targets='${{ needs.PREPARE-job.outputs.targets }}'
              if echo "$targets" | jq -e 'contains(["quay.io"])' > /dev/null 2>&1 && [ "${{ needs.PREPARE-job.outputs.quayio_available }}" = "true" ]; then
                if [ "${{ env.HAS_TEMPLATE }}" = "true" ]; then
                  echo "> **Note:** Each of the ${{ env.VARIANT_COUNT }} variant(s) has been deployed to SHPC registry."
                  echo ""
                  echo "**SHPC Registry Path:** \`/software/setonix/2025.08/pawsey/software/shpc/pawsey_registry/quay.io/pawsey/${IMAGE_NAME}/\`"
                  echo ""
                  echo "**Available Variants:**"
                  matrix_json='${{ needs.PREPARE-job.outputs.build_matrix }}'
                  echo "$matrix_json" | jq -r '.include[] |
                    .values |
                    to_entries |
                    map("-" + (.key | ascii_downcase) + "-" + (.value | ascii_downcase)) |
                    join("") as $suffix |
                    "- \`quay.io/pawsey/'"${IMAGE_NAME}"'" + $suffix + ":'"${VERSION}"'\`"'
                  echo ""
                  echo "### SHPC Usage Commands"
                  echo ""
                  echo "Load and use a specific variant via SHPC:"
                  echo "\`\`\`bash"
                  echo "# Load SHPC module"
                  echo "module load shpc/0.1.32"
                  echo ""
                  echo "# List available variants"
                  first_variant=$(echo "$matrix_json" | jq -r '.include[0].values | to_entries | map("-" + (.key | ascii_downcase) + "-" + (.value | ascii_downcase)) | join("")')
                  first_variant_name="${IMAGE_NAME}${first_variant}"
                  echo "shpc show quay.io/pawsey/${first_variant_name}"
                  echo ""
                  echo "# Install a specific variant (example with first variant)"
                  echo "shpc install quay.io/pawsey/${first_variant_name}:${VERSION}"
                  echo ""
                  echo "# Use the container"
                  echo "shpc run quay.io/pawsey/${first_variant_name}:${VERSION} <command>"
                  echo "\`\`\`"
                else
                  shpc_image="quay.io/pawsey/${IMAGE_NAME}:${VERSION}"
                  echo "| Registry Path | Image Source | Status |"
                  echo "|---------------|--------------|--------|"
                  echo "| \`/software/setonix/2025.08/pawsey/software/shpc/pawsey_registry/quay.io/pawsey/${IMAGE_NAME}/\` | \`$shpc_image\` | âœ… Deployed |"
                  echo ""
                  echo "### SHPC Usage Commands"
                  echo ""
                  echo "Load and use the container via SHPC:"
                  echo "\`\`\`bash"
                  echo "# Load SHPC module"
                  echo "module load shpc/0.1.32"
                  echo ""
                  echo "# Install the container"
                  echo "shpc install $shpc_image"
                  echo ""
                  echo "# Show available commands"
                  echo "shpc show $shpc_image"
                  echo ""
                  echo "# Use the container"
                  echo "shpc run $shpc_image <command>"
                  echo "\`\`\`"
                fi
              fi
            elif [ "${{ needs.DEPLOY-job.result }}" = "failure" ]; then
              echo "| SHPC Registry | N/A | âŒ Deployment Failed |"
            elif [ "${{ needs.DEPLOY-job.result }}" = "skipped" ]; then
              echo "| SHPC Registry | N/A | â­ï¸ Skipped (shpc=false or Quay.io not available or not in targets) |"
            else
              echo "| SHPC Registry | N/A | â¸ï¸ Not Executed |"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Summary - Job Results
        run: |
          {
            echo ""
            echo "## ðŸ“Š Job Results"
            echo ""
            echo "| Job | Status |"
            echo "|-----|--------|"
            echo "| PREPARE | ${{ needs.PREPARE-job.result == 'success' && 'âœ… Success' || 'âŒ Failed' }} |"
            echo "| BUILD | ${{ needs.BUILD-job.result == 'success' && 'âœ… Success' || 'âŒ Failed' }} |"
            echo "| SCAN-AND-REPORT | ${{ needs['SCAN-AND-REPORT-job'].result == 'success' && 'âœ… Success' || (needs['SCAN-AND-REPORT-job'].result == 'skipped' && 'â­ï¸ Skipped (noscan=true)') || 'âŒ Failed' }} |"
            echo "| PUSH-PRIV | ${{ needs.PUSH-PRIV-job.result == 'success' && 'âœ… Success' || 'âŒ Failed' }} |"
            echo "| PUSH-PUBLIC | ${{ needs.PUSH-PUBLIC-job.result == 'success' && 'âœ… Success' || 'âŒ Failed' }} |"
            echo "| DEPLOY | ${{ needs.DEPLOY-job.result == 'success' && 'âœ… Success' || (needs.DEPLOY-job.result == 'skipped' && 'â­ï¸ Skipped') || 'âŒ Failed' }} |"

            echo ""
            echo "---"
            echo "*Generated by Image Manager CI/CD Pipeline v2.0.0*"
          } >> "$GITHUB_STEP_SUMMARY"